{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Deep Learning \ud83d\udd17 Deep Learning section of the Algorithms in Machine Learning class at ISAE-Supaero Home Github repository Adapted from Emmanuel Rachelson's Machine Learning class Syllabus \ud83d\udd17 This class covers deep learning in a total of 24 hours over 5 weeks. We start with simple multi-layer perceptrons, backpropogation, and gradient descent, exploring at the fundamental aspects of deep learning in depth. We cover a wide range of deep learning topics, from Natural Language Processing to Generative Adversarial Networks; the full schedule is below. The goal is that students understand the capacities of deep learning, the current state of the field, and the challenges of using and developing deep learning algorithms. By the end of this class, we expect students that students will be able to understand recent literature in deep learning, implement novel neural network architectures, use and understand the PyTorch library in many ways, and apply deep learning to different domains. 2020 Schedule \ud83d\udd17 Schedule 17/11 Artificial Neural Networks ANNs, backpropagation, Stochastic Gradient Descent 23/11 Deep Learning layers, convolution, architectures, training 30/11 Deep Learning for Computer Vision, pt 1 Convolutional Neural Networks, satellite imagery 01/12 Deep Learning for Computer Vision, pt 2 07/12 RNNs Recurrent Neural Networks, LSTM, GRU 08/12 NLP Natural Language Processing, Transformers 15/12 GANs Generative Adversarial Networks, CycleGAN 16/12 Dimensionality Reduction Autoencoders, t-SNE","title":"Deep Learning"},{"location":"index.html#deep-learning","text":"Deep Learning section of the Algorithms in Machine Learning class at ISAE-Supaero Home Github repository Adapted from Emmanuel Rachelson's Machine Learning class","title":"Deep Learning"},{"location":"index.html#syllabus","text":"This class covers deep learning in a total of 24 hours over 5 weeks. We start with simple multi-layer perceptrons, backpropogation, and gradient descent, exploring at the fundamental aspects of deep learning in depth. We cover a wide range of deep learning topics, from Natural Language Processing to Generative Adversarial Networks; the full schedule is below. The goal is that students understand the capacities of deep learning, the current state of the field, and the challenges of using and developing deep learning algorithms. By the end of this class, we expect students that students will be able to understand recent literature in deep learning, implement novel neural network architectures, use and understand the PyTorch library in many ways, and apply deep learning to different domains.","title":"Syllabus"},{"location":"index.html#2020-schedule","text":"Schedule 17/11 Artificial Neural Networks ANNs, backpropagation, Stochastic Gradient Descent 23/11 Deep Learning layers, convolution, architectures, training 30/11 Deep Learning for Computer Vision, pt 1 Convolutional Neural Networks, satellite imagery 01/12 Deep Learning for Computer Vision, pt 2 07/12 RNNs Recurrent Neural Networks, LSTM, GRU 08/12 NLP Natural Language Processing, Transformers 15/12 GANs Generative Adversarial Networks, CycleGAN 16/12 Dimensionality Reduction Autoencoders, t-SNE","title":"2020 Schedule"},{"location":"ANN.html","text":"Artificial Neural Networks \ud83d\udd17 Home Github repository This class gives a biological and historical overview of artificial neural networks and walks through the theoretical foundations of backpropagation and gradient descent, using an example in numpy. Notebook As an additional exercise, this notebook runs the provided backpropagation code, visualizing neural activations and error at each step. Visualizing backprop Additional Resources \ud83d\udd17 In class we present a Universal Approximation Theorem for single-layer networks with sigmoid activation functions. The slides for that proof are here: Universal Approximation Theorem This online book has a nice interactive visualization of this property of neural networks. The deep learning book is fully available online and contains many great examples. Notebook versions of those examples are available here Stanford CS229 Lectures 11 and 12 introduce ANNs, backpropagation, and gradient descent, with lecture 12 going further in depth on how to resolve common training problems in ANNs.","title":"Artificial Neural Networks"},{"location":"ANN.html#artificial-neural-networks","text":"Home Github repository This class gives a biological and historical overview of artificial neural networks and walks through the theoretical foundations of backpropagation and gradient descent, using an example in numpy. Notebook As an additional exercise, this notebook runs the provided backpropagation code, visualizing neural activations and error at each step. Visualizing backprop","title":"Artificial Neural Networks"},{"location":"ANN.html#additional-resources","text":"In class we present a Universal Approximation Theorem for single-layer networks with sigmoid activation functions. The slides for that proof are here: Universal Approximation Theorem This online book has a nice interactive visualization of this property of neural networks. The deep learning book is fully available online and contains many great examples. Notebook versions of those examples are available here Stanford CS229 Lectures 11 and 12 introduce ANNs, backpropagation, and gradient descent, with lecture 12 going further in depth on how to resolve common training problems in ANNs.","title":"Additional Resources"},{"location":"DR.html","text":"Dimensionality Reduction \ud83d\udd17 Home Github repository","title":"Dimensionality Reduction"},{"location":"DR.html#dimensionality-reduction","text":"Home Github repository","title":"Dimensionality Reduction"},{"location":"GAN.html","text":"Generative Adversarial Networks \ud83d\udd17 Home Github repository","title":"GANs"},{"location":"GAN.html#generative-adversarial-networks","text":"Home Github repository","title":"Generative Adversarial Networks"},{"location":"NLP.html","text":"Natural Language Processing \ud83d\udd17 Home Github repository","title":"NLP"},{"location":"NLP.html#natural-language-processing","text":"Home Github repository","title":"Natural Language Processing"},{"location":"RNN.html","text":"Recurrent Neural Networks \ud83d\udd17 Home Github repository Notebook Additional Resources \ud83d\udd17 Time series forecasting tutorial in Tensorflow. Stanford's CS231n lecture on Recurrent Neural Networks, covering RNNs, backpropagation through time, and LSTMs. The deep learning book is fully available online and contains many great examples. Notebook versions of those examples are available here . Chapter 10 covers recurrent neural networks.","title":"RNNs"},{"location":"RNN.html#recurrent-neural-networks","text":"Home Github repository Notebook","title":"Recurrent Neural Networks"},{"location":"RNN.html#additional-resources","text":"Time series forecasting tutorial in Tensorflow. Stanford's CS231n lecture on Recurrent Neural Networks, covering RNNs, backpropagation through time, and LSTMs. The deep learning book is fully available online and contains many great examples. Notebook versions of those examples are available here . Chapter 10 covers recurrent neural networks.","title":"Additional Resources"},{"location":"deep.html","text":"Deep Learning \ud83d\udd17 Home Github repository In this class, we construct simple deep ANNs using the PyTorch library on the Fashion MNIST example. Notebook source Notebook on Colab Neural Architecture Slides Instead of calculating backpropagation by hand as in the first class , this class uses automatic differentiation built in to PyTorch. This is built on the autograd package which has its own tutorial . One important concept is convolutional neural network layers. The Stanford CS231N class has a good interactive demonstration of convolution. This page shows demonstrations of stride, padding, and dilation. To facilitate the use of Torch, we introduce ignite at the end of class. An example of using ignite is given in this notebook Additional Resources \ud83d\udd17 The deep learning book is fully available online and contains many great examples. Notebook versions of those examples are available here . Chapter 9 specifically covers convolutional neural networks.","title":"Deep Learning"},{"location":"deep.html#deep-learning","text":"Home Github repository In this class, we construct simple deep ANNs using the PyTorch library on the Fashion MNIST example. Notebook source Notebook on Colab Neural Architecture Slides Instead of calculating backpropagation by hand as in the first class , this class uses automatic differentiation built in to PyTorch. This is built on the autograd package which has its own tutorial . One important concept is convolutional neural network layers. The Stanford CS231N class has a good interactive demonstration of convolution. This page shows demonstrations of stride, padding, and dilation. To facilitate the use of Torch, we introduce ignite at the end of class. An example of using ignite is given in this notebook","title":"Deep Learning"},{"location":"deep.html#additional-resources","text":"The deep learning book is fully available online and contains many great examples. Notebook versions of those examples are available here . Chapter 9 specifically covers convolutional neural networks.","title":"Additional Resources"},{"location":"vision.html","text":"Deep Learning for Computer Vision \ud83d\udd17 Home Github repository Class materials here Deep Learning for Computer Vision , practical session at ISAE-SUPAERO \ud83d\udd17 Introduction \ud83d\udd17 This repository contains the code and documentation of a \"Deep Learning practical session\" given at ISAE-SUPAERO on December 2nd/3rd 2019 and Nov 30/Dec 1st 2020 The introduction slides can be accessed at this URL website . It is recommended to read it first as it contains the necessary information to run this from scratch. There are three notebooks at the root of this repository, those as the exercises Where to run it ? \ud83d\udd17 This hands on session is based on running code & training using Google Cloud Platform Deep Learning VMs , see gcp/ for examples on configuring your own machine. However, this is runnable everywhere since data access is based on public URLs & numpy Should you want to do this at home you can use Google Collaboratory instances - it's even easier than deep learning VMs Usage & Contribution \ud83d\udd17 No support is guaranteed by the authors beyond the hands-on session. This hands-on session was created by Florient Chouteau and Matthieu Le Goff. See licence.md for licence information.","title":"Deep Learning for Computer Vision"},{"location":"vision.html#deep-learning-for-computer-vision","text":"Home Github repository Class materials here","title":"Deep Learning for Computer Vision"},{"location":"vision.html#deep-learning-for-computer-vision-practical-session-at-isae-supaero","text":"","title":"Deep Learning for Computer Vision , practical session at ISAE-SUPAERO"},{"location":"vision.html#introduction","text":"This repository contains the code and documentation of a \"Deep Learning practical session\" given at ISAE-SUPAERO on December 2nd/3rd 2019 and Nov 30/Dec 1st 2020 The introduction slides can be accessed at this URL website . It is recommended to read it first as it contains the necessary information to run this from scratch. There are three notebooks at the root of this repository, those as the exercises","title":"Introduction"},{"location":"vision.html#where-to-run-it","text":"This hands on session is based on running code & training using Google Cloud Platform Deep Learning VMs , see gcp/ for examples on configuring your own machine. However, this is runnable everywhere since data access is based on public URLs & numpy Should you want to do this at home you can use Google Collaboratory instances - it's even easier than deep learning VMs","title":"Where to run it ?"},{"location":"vision.html#usage-contribution","text":"No support is guaranteed by the authors beyond the hands-on session. This hands-on session was created by Florient Chouteau and Matthieu Le Goff. See licence.md for licence information.","title":"Usage &amp; Contribution"}]}